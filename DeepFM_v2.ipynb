{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import timeit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import os\n",
    "model_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_df(db,table):\n",
    "    '''fetch table from database'''\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',database='bid',user='root',password='kinglu92jaychou')\n",
    "        sql_select_Query = \"select * from \" + db + \".\" + table\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(sql_select_Query)\n",
    "        # get all records\n",
    "        records = cursor.fetchall()\n",
    "        print(\"Total number of rows in table: \", cursor.rowcount)\n",
    "        return records\n",
    "    except mysql.connector.Error as e:\n",
    "        print(\"Error reading data from MySQL table\", e)\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            connection.close()\n",
    "            cursor.close()\n",
    "            print(\"MySQL connection is closed\")\n",
    "\n",
    "\n",
    "def vectorized_input(df):\n",
    "    # For ipinyou data, has to be changed when applying to the real data\n",
    "    categorical_fields = ['weekday', 'hour', 'logtype',\n",
    "                          'useragent', 'region', 'city', 'adexchange',\n",
    "                          'slotwidth', 'slotheight',\n",
    "                          'slotvisibility', 'slotformat', 'slotprice', 'creative',\n",
    "                          'keypage', 'advertiser']\n",
    "\n",
    "    one_hot_list = []\n",
    "    # each element represent a sparse matrix with size (#observations, onehot length)\n",
    "    for categorical_field in categorical_fields:\n",
    "        enc = OneHotEncoder()\n",
    "        one_hot_list.append(enc.fit_transform(np.array(df[categorical_field]).reshape(-1,1)))\n",
    "    output = np.array(df.click)\n",
    "\n",
    "    # Concate all the variables row-wise\n",
    "    fields = list(sub1+sub2+sub3+sub4+sub5+sub6+sub7+sub8+sub9+sub10+sub11+sub12+sub13+sub14+sub15 for\n",
    "             sub1,sub2,sub3,sub4,sub5,sub6,sub7,sub8,sub9,sub10,sub11,sub12,sub13,sub14,sub15 in \n",
    "             zip(one_hot_list[0].toarray().tolist(),\n",
    "                 one_hot_list[1].toarray().tolist(),\n",
    "                 one_hot_list[2].toarray().tolist(),\n",
    "                 one_hot_list[3].toarray().tolist(),\n",
    "                 one_hot_list[4].toarray().tolist(),\n",
    "                 one_hot_list[5].toarray().tolist(),\n",
    "                 one_hot_list[6].toarray().tolist(),\n",
    "                 one_hot_list[7].toarray().tolist(),\n",
    "                 one_hot_list[8].toarray().tolist(),\n",
    "                 one_hot_list[9].toarray().tolist(),\n",
    "                 one_hot_list[10].toarray().tolist(),\n",
    "                 one_hot_list[11].toarray().tolist(),\n",
    "                 one_hot_list[12].toarray().tolist(),\n",
    "                 one_hot_list[13].toarray().tolist(),\n",
    "                 one_hot_list[14].toarray().tolist()))\n",
    "                 \n",
    "    fields = np.matrix(fields)\n",
    "    output.shape += (1, )\n",
    "    return fields,output\n",
    "\n",
    "\n",
    "def evaluate_recall(truth, predictions):  \n",
    "    recall = recall_score(truth, predictions.round())\n",
    "    return ('recall', recall, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_df('bid','train_data')\n",
    "df = pd.DataFrame(data,columns = ['click','weekday','hour','bidid','timestamp','logtype','ipinyouid',\n",
    "                                  'useragent','IP','region','city','adexchange','domain','url','urlid',\n",
    "                                  'slotid','slotwidth','slotheight','slotvisibility','slotformat','slotprice',\n",
    "                                  'creative','bidprice','payprice','keypage','advertiser','usertag'])\n",
    "df.usertag = df.usertag.str.rstrip('\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields,output = vectorized_input(df[0:200000])\n",
    "fields,output = vectorized_input(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fields, output, test_size=0.3,random_state=42,stratify=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = ADASYN(random_state=0,sampling_strategy=0.6)\n",
    "X_train,y_train = ada.fit_resample(X_train,y_train) # minority / majority = 0.6 after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize layers\n",
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, p):\n",
    "        super(Linear, self).__init__()\n",
    "        # bias and weights\n",
    "        self.w0 = tf.Variable(tf.zeros([1]),trainable=True,dtype=tf.float32)\n",
    "        self.W = tf.Variable(tf.zeros([p]),trainable=True,dtype=tf.float32)\n",
    "    def call(self, inputs):\n",
    "        return tf.add(self.w0,tf.reduce_sum(tf.multiply(self.W,inputs),axis=1,keepdims=True))\n",
    "\n",
    "class Latent(keras.layers.Layer):\n",
    "    def __init__(self,k,p):\n",
    "        super(Latent, self).__init__()\n",
    "        #latent(interaction) vector, to measure the impact of interactions with other features\n",
    "        self.V = tf.Variable(tf.random.normal(shape=[k,p]),trainable=True,dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, tf.transpose(self.V))\n",
    "\n",
    "class Interaction(Latent):\n",
    "    def __init__(self,latent_layer):\n",
    "        super(Interaction, self).__init__(k,p)\n",
    "        self.V = latent_layer.V\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.multiply(0.5,\n",
    "                    tf.reduce_sum(\n",
    "                        tf.subtract(\n",
    "                            tf.pow(tf.matmul(inputs, tf.transpose(self.V)), 2),\n",
    "                            tf.matmul(tf.pow(inputs, 2), tf.transpose(tf.pow(self.V, 2)))),\n",
    "                        1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_bias = np.log(sum(y_train==1) / (y_train.shape[0]-sum(y_train==1))) # Introduce bias \n",
    "# output_bais = tf.keras.initializers.Constant(initial_bias)\n",
    "# FM Component\n",
    "n,p = X_train.shape\n",
    "# number of latent factors \n",
    "k = 10\n",
    "\n",
    "X = keras.Input(shape=(p),name='Field')\n",
    "\n",
    "latent_layer = Latent(k,p)\n",
    "X_latent = latent_layer(X)\n",
    "\n",
    "linear_layer = Linear(p)\n",
    "linear_term = linear_layer(X)\n",
    "\n",
    "interaction_layer = Interaction(latent_layer)\n",
    "interaction_term = interaction_layer(X)\n",
    "\n",
    "y_FM = layers.Dense(1,activation='sigmoid')(tf.add(linear_term,interaction_term))\n",
    "\n",
    "# Deep Component\n",
    "X_deep = layers.Dense(400, activation='relu',name='First_Layer_DNN')(X_latent)\n",
    "X_deep = layers.Dropout(0.7)(X_deep)\n",
    "X_deep = layers.Dense(400, activation='relu', name='Second_Layer_DNN')(X_deep)\n",
    "X_deep = layers.Dropout(0.7)(X_deep)\n",
    "X_deep = layers.Dense(400, activation='relu', name='Third_Layer_DNN')(X_deep)\n",
    "y_DNN = layers.Dense(1,activation='sigmoid', name='DNN_output')(X_deep)\n",
    "\n",
    "yhat = layers.Dense(1,activation='sigmoid',name='yhat')(tf.math.add(y_FM,y_DNN))\n",
    "\n",
    "model = Model(inputs = X, outputs = yhat)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_recall', \n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=METRICS)\n",
    "logs = model.fit(X_train, \n",
    "                y_train, \n",
    "                epochs=100, \n",
    "                batch_size=64, \n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, y_test),\n",
    "                validation_split = 0.2, \n",
    "                validation_freq = 1, \n",
    "                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('DeepFM_V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b05ccce202e97ea170533ef02d00dca16ad94694ffea7539d6bdc21bb0bbc073"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
