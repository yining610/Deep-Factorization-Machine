{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import timeit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import os\n",
    "model_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_df(db,table):\n",
    "    '''fetch table from database'''\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',database='bid',user='root',password='yining610')\n",
    "        sql_select_Query = \"select * from \" + db + \".\" + table\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(sql_select_Query)\n",
    "        # get all records\n",
    "        records = cursor.fetchall()\n",
    "        print(\"Total number of rows in table: \", cursor.rowcount)\n",
    "        return records\n",
    "    except mysql.connector.Error as e:\n",
    "        print(\"Error reading data from MySQL table\", e)\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            connection.close()\n",
    "            cursor.close()\n",
    "            print(\"MySQL connection is closed\")\n",
    "\n",
    "\n",
    "def vectorized_input(df):\n",
    "    # For ipinyou data, has to be changed when applying to the real data\n",
    "    categorical_fields = ['weekday', 'hour', 'logtype',\n",
    "                          'useragent', 'region', 'city', 'adexchange',\n",
    "                          'slotwidth', 'slotheight',\n",
    "                          'slotvisibility', 'slotformat', 'slotprice', 'creative',\n",
    "                          'keypage', 'advertiser']\n",
    "\n",
    "    one_hot_list = []\n",
    "    # each element represent a sparse matrix with size (#observations, onehot length)\n",
    "    for categorical_field in categorical_fields:\n",
    "        enc = OneHotEncoder()\n",
    "        one_hot_list.append(enc.fit_transform(np.array(df[categorical_field]).reshape(-1,1)))\n",
    "    output = np.array(df.click)\n",
    "\n",
    "    # Concate all the variables row-wise\n",
    "    fields = list(sub1+sub2+sub3+sub4+sub5+sub6+sub7+sub8+sub9+sub10+sub11+sub12+sub13+sub14+sub15 for\n",
    "             sub1,sub2,sub3,sub4,sub5,sub6,sub7,sub8,sub9,sub10,sub11,sub12,sub13,sub14,sub15 in \n",
    "             zip(one_hot_list[0].toarray().tolist(),\n",
    "                 one_hot_list[1].toarray().tolist(),\n",
    "                 one_hot_list[2].toarray().tolist(),\n",
    "                 one_hot_list[3].toarray().tolist(),\n",
    "                 one_hot_list[4].toarray().tolist(),\n",
    "                 one_hot_list[5].toarray().tolist(),\n",
    "                 one_hot_list[6].toarray().tolist(),\n",
    "                 one_hot_list[7].toarray().tolist(),\n",
    "                 one_hot_list[8].toarray().tolist(),\n",
    "                 one_hot_list[9].toarray().tolist(),\n",
    "                 one_hot_list[10].toarray().tolist(),\n",
    "                 one_hot_list[11].toarray().tolist(),\n",
    "                 one_hot_list[12].toarray().tolist(),\n",
    "                 one_hot_list[13].toarray().tolist(),\n",
    "                 one_hot_list[14].toarray().tolist()))\n",
    "                 \n",
    "    fields = np.matrix(fields)\n",
    "    output.shape += (1, )\n",
    "    return fields,output\n",
    "\n",
    "\n",
    "def evaluate_recall(truth, predictions):  \n",
    "    recall = recall_score(truth, predictions.round())\n",
    "    return ('recall', recall, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in table:  1048575\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "data = fetch_df('bid','train_data')\n",
    "df = pd.DataFrame(data,columns = ['click','weekday','hour','bidid','timestamp','logtype','ipinyouid',\n",
    "                                  'useragent','IP','region','city','adexchange','domain','url','urlid',\n",
    "                                  'slotid','slotwidth','slotheight','slotvisibility','slotformat','slotprice',\n",
    "                                  'creative','bidprice','payprice','keypage','advertiser','usertag'])\n",
    "df.usertag = df.usertag.str.rstrip('\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields,output = vectorized_input(df[0:200000])\n",
    "fields,output = vectorized_input(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fields, output, test_size=0.3,random_state=42,stratify=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\610\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(random_state=0,sampling_strategy=0.6)\n",
    "X_train,y_train = ada.fit_resample(X_train,y_train) # minority / majority = 0.6 after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440176"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([222])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize layers\n",
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, p):\n",
    "        super(Linear, self).__init__()\n",
    "        # bias and weights\n",
    "        self.w0 = tf.Variable(tf.zeros([1]),trainable=True,dtype=tf.float32)\n",
    "        self.W = tf.Variable(tf.zeros([p]),trainable=True,dtype=tf.float32)\n",
    "    def call(self, inputs):\n",
    "        return tf.add(self.w0,tf.reduce_sum(tf.multiply(self.W,inputs),axis=1,keepdims=True))\n",
    "\n",
    "class Latent(keras.layers.Layer):\n",
    "    def __init__(self,k,p):\n",
    "        super(Latent, self).__init__()\n",
    "        #latent(interaction) vector, to measure the impact of interactions with other features\n",
    "        self.V = tf.Variable(tf.random.normal(shape=[k,p]),trainable=True,dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, tf.transpose(self.V))\n",
    "\n",
    "class Interaction(Latent):\n",
    "    def __init__(self,latent_layer):\n",
    "        super(Interaction, self).__init__(k,p)\n",
    "        self.V = latent_layer.V\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.multiply(0.5,\n",
    "                    tf.reduce_sum(\n",
    "                        tf.subtract(\n",
    "                            tf.pow(tf.matmul(inputs, tf.transpose(self.V)), 2),\n",
    "                            tf.matmul(tf.pow(inputs, 2), tf.transpose(tf.pow(self.V, 2)))),\n",
    "                        1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Field (InputLayer)             [(None, 967)]        0           []                               \n",
      "                                                                                                  \n",
      " latent_1 (Latent)              (None, 10)           9670        ['Field[0][0]']                  \n",
      "                                                                                                  \n",
      " First_Layer_DNN (Dense)        (None, 400)          4400        ['latent_1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 400)          0           ['First_Layer_DNN[0][0]']        \n",
      "                                                                                                  \n",
      " Second_Layer_DNN (Dense)       (None, 400)          160400      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " linear_1 (Linear)              (None, 1)            968         ['Field[0][0]']                  \n",
      "                                                                                                  \n",
      " interaction_1 (Interaction)    (None, 1)            9670        ['Field[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 400)          0           ['Second_Layer_DNN[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.add_2 (TFOpLambda)     (None, 1)            0           ['linear_1[0][0]',               \n",
      "                                                                  'interaction_1[0][0]']          \n",
      "                                                                                                  \n",
      " Third_Layer_DNN (Dense)        (None, 400)          160400      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2           ['tf.math.add_2[0][0]']          \n",
      "                                                                                                  \n",
      " DNN_output (Dense)             (None, 1)            401         ['Third_Layer_DNN[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.add_3 (TFOpLambda)     (None, 1)            0           ['dense_1[0][0]',                \n",
      "                                                                  'DNN_output[0][0]']             \n",
      "                                                                                                  \n",
      " yhat (Dense)                   (None, 1)            2           ['tf.math.add_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 336,243\n",
      "Trainable params: 336,243\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initial_bias = np.log(sum(y_train==1) / (y_train.shape[0]-sum(y_train==1))) # Introduce bias \n",
    "# output_bais = tf.keras.initializers.Constant(initial_bias)\n",
    "# FM Component\n",
    "n,p = X_train.shape\n",
    "# number of latent factors \n",
    "k = 10\n",
    "\n",
    "X = keras.Input(shape=(p),name='Field')\n",
    "\n",
    "latent_layer = Latent(k,p)\n",
    "X_latent = latent_layer(X)\n",
    "\n",
    "linear_layer = Linear(p)\n",
    "linear_term = linear_layer(X)\n",
    "\n",
    "interaction_layer = Interaction(latent_layer)\n",
    "interaction_term = interaction_layer(X)\n",
    "\n",
    "y_FM = layers.Dense(1,activation='sigmoid')(tf.add(linear_term,interaction_term))\n",
    "\n",
    "# Deep Component\n",
    "X_deep = layers.Dense(400, activation='relu',name='First_Layer_DNN')(X_latent)\n",
    "X_deep = layers.Dropout(0.7)(X_deep)\n",
    "X_deep = layers.Dense(400, activation='relu', name='Second_Layer_DNN')(X_deep)\n",
    "X_deep = layers.Dropout(0.7)(X_deep)\n",
    "X_deep = layers.Dense(400, activation='relu', name='Third_Layer_DNN')(X_deep)\n",
    "y_DNN = layers.Dense(1,activation='sigmoid', name='DNN_output')(X_deep)\n",
    "\n",
    "yhat = layers.Dense(1,activation='sigmoid',name='yhat')(tf.math.add(y_FM,y_DNN))\n",
    "\n",
    "model = Model(inputs = X, outputs = yhat)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_recall', \n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14671/14671 [==============================] - 186s 13ms/step - loss: 0.4441 - tp: 72317.0000 - fp: 22779.0000 - tn: 710704.0000 - fn: 133127.0000 - accuracy: 0.8340 - precision: 0.7605 - recall: 0.3520 - auc: 0.7022 - prc: 0.5446 - val_loss: 1.4116 - val_tp: 74459.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 160273.0000 - val_accuracy: 0.3172 - val_precision: 1.0000 - val_recall: 0.3172 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 2/100\n",
      "14671/14671 [==============================] - 189s 13ms/step - loss: 0.2927 - tp: 131531.0000 - fp: 10963.0000 - tn: 722520.0000 - fn: 73913.0000 - accuracy: 0.9096 - precision: 0.9231 - recall: 0.6402 - auc: 0.8413 - prc: 0.7761 - val_loss: 1.3781 - val_tp: 106970.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 127762.0000 - val_accuracy: 0.4557 - val_precision: 1.0000 - val_recall: 0.4557 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 3/100\n",
      "14671/14671 [==============================] - 189s 13ms/step - loss: 0.2000 - tp: 164108.0000 - fp: 10107.0000 - tn: 723376.0000 - fn: 41336.0000 - accuracy: 0.9452 - precision: 0.9420 - recall: 0.7988 - auc: 0.9185 - prc: 0.8784 - val_loss: 1.3227 - val_tp: 132838.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 101894.0000 - val_accuracy: 0.5659 - val_precision: 1.0000 - val_recall: 0.5659 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 4/100\n",
      "14671/14671 [==============================] - 242s 16ms/step - loss: 0.0963 - tp: 192197.0000 - fp: 10882.0000 - tn: 722601.0000 - fn: 13247.0000 - accuracy: 0.9743 - precision: 0.9464 - recall: 0.9355 - auc: 0.9837 - prc: 0.9627 - val_loss: 1.1830 - val_tp: 166301.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 68431.0000 - val_accuracy: 0.7085 - val_precision: 1.0000 - val_recall: 0.7085 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 5/100\n",
      "14671/14671 [==============================] - 189s 13ms/step - loss: 0.0456 - tp: 200855.0000 - fp: 7706.0000 - tn: 725777.0000 - fn: 4589.0000 - accuracy: 0.9869 - precision: 0.9631 - recall: 0.9777 - auc: 0.9960 - prc: 0.9867 - val_loss: 1.1024 - val_tp: 180324.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 54408.0000 - val_accuracy: 0.7682 - val_precision: 1.0000 - val_recall: 0.7682 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 6/100\n",
      "14671/14671 [==============================] - 184s 13ms/step - loss: 0.0324 - tp: 202072.0000 - fp: 5867.0000 - tn: 727616.0000 - fn: 3372.0000 - accuracy: 0.9902 - precision: 0.9718 - recall: 0.9836 - auc: 0.9981 - prc: 0.9924 - val_loss: 1.1132 - val_tp: 182432.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 52300.0000 - val_accuracy: 0.7772 - val_precision: 1.0000 - val_recall: 0.7772 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 7/100\n",
      "14671/14671 [==============================] - 187s 13ms/step - loss: 0.0267 - tp: 202399.0000 - fp: 4846.0000 - tn: 728637.0000 - fn: 3045.0000 - accuracy: 0.9916 - precision: 0.9766 - recall: 0.9852 - auc: 0.9987 - prc: 0.9945 - val_loss: 1.0608 - val_tp: 187919.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 46813.0000 - val_accuracy: 0.8006 - val_precision: 1.0000 - val_recall: 0.8006 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 8/100\n",
      "14671/14671 [==============================] - 190s 13ms/step - loss: 0.0237 - tp: 202614.0000 - fp: 4262.0000 - tn: 729221.0000 - fn: 2830.0000 - accuracy: 0.9924 - precision: 0.9794 - recall: 0.9862 - auc: 0.9990 - prc: 0.9958 - val_loss: 1.1238 - val_tp: 186981.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 47751.0000 - val_accuracy: 0.7966 - val_precision: 1.0000 - val_recall: 0.7966 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 9/100\n",
      "14671/14671 [==============================] - 192s 13ms/step - loss: 0.0216 - tp: 202714.0000 - fp: 3888.0000 - tn: 729595.0000 - fn: 2730.0000 - accuracy: 0.9930 - precision: 0.9812 - recall: 0.9867 - auc: 0.9991 - prc: 0.9966 - val_loss: 1.0926 - val_tp: 189586.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 45146.0000 - val_accuracy: 0.8077 - val_precision: 1.0000 - val_recall: 0.8077 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 10/100\n",
      " 6128/14671 [===========>..................] - ETA: 1:36 - loss: 0.0202 - tp: 84741.0000 - fp: 1479.0000 - tn: 304819.0000 - fn: 1153.0000 - accuracy: 0.9933 - precision: 0.9828 - recall: 0.9866 - auc: 0.9992 - prc: 0.9970"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19652/926025181.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     metrics=METRICS)\n\u001b[1;32m----> 5\u001b[1;33m logs = model.fit(X_train, \n\u001b[0m\u001b[0;32m      6\u001b[0m                 \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=METRICS)\n",
    "logs = model.fit(X_train, \n",
    "                y_train, \n",
    "                epochs=100, \n",
    "                batch_size=64, \n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, y_test),\n",
    "                validation_split = 0.2, \n",
    "                validation_freq = 1, \n",
    "                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Field with unsupported characters which will be renamed to field in the SavedModel.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Tried to export a function which references 'untracked' resource Tensor(\"1811471:0\", shape=(), dtype=resource). TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\n\n Trackable Python objects referring to this tensor (from gc.get_referrers, limited to two hops):\n<tf.Variable 'Variable:0' shape=(967,) dtype=float32>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20732/2269593338.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DeepFM_V2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36m_map_captures_to_created_tensors\u001b[1;34m(original_captures, resource_map)\u001b[0m\n\u001b[0;32m    523\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecondary_referrer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrackable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mtrackable_referrers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecondary_referrer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m       raise AssertionError(\n\u001b[0m\u001b[0;32m    526\u001b[0m           \u001b[1;34m\"Tried to export a function which references 'untracked' resource \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m           \u001b[1;34mf\"{interior}. TensorFlow objects (e.g. tf.Variable) captured by \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Tried to export a function which references 'untracked' resource Tensor(\"1811471:0\", shape=(), dtype=resource). TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\n\n Trackable Python objects referring to this tensor (from gc.get_referrers, limited to two hops):\n<tf.Variable 'Variable:0' shape=(967,) dtype=float32>"
     ]
    }
   ],
   "source": [
    "model.save('DeepFM_V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b05ccce202e97ea170533ef02d00dca16ad94694ffea7539d6bdc21bb0bbc073"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
